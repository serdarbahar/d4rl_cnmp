{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.distributions as D\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def log_prob_loss(output, y_target): \n",
    "    mean, std = output.chunk(2, dim=-1)\n",
    "    std = F.softplus(std)\n",
    "    dist = D.Normal(loc=mean, scale=std)\n",
    "    return -torch.mean(dist.log_prob(y_target)) \n",
    "\n",
    "class CNMP(nn.Module):\n",
    "    def __init__(self, d_x, d_y, d_SM):\n",
    "        super(CNMP, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(d_x + d_y, 64), nn.LayerNorm(64), nn.ReLU(),\n",
    "            nn.Linear(64, 64), nn.LayerNorm(64), nn.ReLU(),\n",
    "            nn.Linear(64, 128), nn.LayerNorm(128), nn.ReLU(),\n",
    "            nn.Linear(128, 256), nn.LayerNorm(256), nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(d_x + (15) + 256, 512), nn.LayerNorm(512), nn.ReLU(),\n",
    "            nn.Linear(512, 512), nn.LayerNorm(512), nn.ReLU(),\n",
    "            nn.Linear(512, 512), nn.LayerNorm(512), nn.ReLU(),\n",
    "            nn.Linear(512, 256), nn.LayerNorm(256), nn.ReLU(),\n",
    "            nn.Linear(256, 128), nn.LayerNorm(128), nn.ReLU(),\n",
    "            nn.Linear(128, 2 * d_SM)  # Output mean and std for\n",
    "        )\n",
    "    def forward(self, obs, context, mask, x_tar): # obs is (n, d_x + d_y)\n",
    "\n",
    "        r = self.encoder(obs)\n",
    "        masked_r = torch.bmm(mask, r)\n",
    "        masked_r_sum = torch.sum(masked_r, dim=1, keepdim=True)  # (1, 128)\n",
    "        r_avg = masked_r_sum / torch.sum(mask, dim=[1,2], keepdim=True)  # (1, 128)\n",
    "        r_avg = r_avg.repeat(1, x_tar.shape[1], 1)\n",
    "        context = context.unsqueeze(1).repeat(1, x_tar.shape[1], 1)  # (n, 1, 9)\n",
    "        concat = torch.cat((r_avg, context, x_tar), dim=-1)\n",
    "        #concat = torch.cat((r_avg, x_tar), dim=-1)\n",
    "        output = self.decoder(concat) # (2*d_y,)\n",
    "        return output, r_avg\n",
    "\n",
    "# gets random number of random obs. points from a random trajectory. Also gets a \n",
    "# random target (x,y) from the same trajectory\n",
    "def get_training_sample(d_SM, batch_size):\n",
    "\n",
    "    n = np.random.randint(0, OBS_MAX, batch_size) + 1  # number of observations\n",
    "    perm = np.random.permutation(d_N)\n",
    "    d = perm[:batch_size]  # select random trajectories\n",
    "\n",
    "    observations = np.zeros((batch_size, OBS_MAX, d_x + d_y))\n",
    "    context = np.zeros((batch_size, 15))\n",
    "    target_X = np.zeros((batch_size, 1, d_x))\n",
    "    target_Y = np.zeros((batch_size, 1, d_SM))\n",
    "    mask = np.zeros((batch_size, OBS_MAX, OBS_MAX))\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        perm = np.random.permutation(time_len)\n",
    "        observations[i,:n[i],:d_x] = X[d[i],perm[:n[i]]]\n",
    "        observations[i,:n[i],d_x:d_x+d_y] = Y[d[i],perm[:n[i]]]\n",
    "        #context[i,:] = np.concat((C[d[i]], O[d[i], perm[n[i]]]), axis=-1)\n",
    "        context[i,:] = C[d[i]]\n",
    "        target_X[i,0] = X[d[i],perm[n[i]]]\n",
    "        target_Y[i,0] = Y[d[i],perm[n[i]],:d_SM]\n",
    "        mask[i,:n[i],:n[i]] = 1\n",
    "    \n",
    "    return torch.from_numpy(observations), torch.from_numpy(context), \\\n",
    "            torch.from_numpy(target_X), torch.from_numpy(target_Y), torch.from_numpy(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import validation\n",
    "import importlib\n",
    "importlib.reload(validation)\n",
    "\n",
    "time_len = 451\n",
    "\n",
    "action_data = np.load('data/reach_arm_actions_v1.npy')  # shape (25, 451, 30)\n",
    "observation_data = np.load('data/reach_arm_observations_v1.npy')  # shape (25, 451, 42)\n",
    "print('Action data shape:', action_data.shape)\n",
    "num_data = action_data.shape[0]\n",
    "\n",
    "X = np.tile(np.linspace(0, 1, time_len).reshape((1, time_len, 1)), (num_data, 1, 1))  # 25 trajectories\n",
    "Y = np.zeros((num_data, time_len, 5))\n",
    "Y[:, 1:] = action_data\n",
    "C = np.zeros((num_data, 15))\n",
    "for i in range(num_data):\n",
    "    C[i, :9] = observation_data[i, 0, 30:39]\n",
    "    C[i, 9:] = observation_data[i, 0, 42:]  # add the first observation as context\n",
    "\n",
    "# normalize Y and C by dimensions\n",
    "for dim in range(Y.shape[-1]):\n",
    "    Y_min = np.min(Y[:, :, dim], axis=(0, 1), keepdims=True)\n",
    "    Y_max = np.max(Y[:, :, dim], axis=(0, 1), keepdims=True)\n",
    "    Y[:, :, dim] = (Y[:, :, dim] - Y_min) / (Y_max - Y_min + 1e-8)\n",
    "for dim in range(C.shape[-1]):\n",
    "    C_min = np.min(C[:, dim], axis=0, keepdims=True)\n",
    "    C_max = np.max(C[:, dim], axis=0, keepdims=True)\n",
    "    C[:, dim] = (C[:, dim] - C_min) / (C_max - C_min + 1e-8)\n",
    "\n",
    "OBS_MAX = 10\n",
    "d_x = X.shape[-1]\n",
    "d_y = Y.shape[-1]\n",
    "d_SM = d_y\n",
    "d_N = Y.shape[0]\n",
    "batch_size = 8\n",
    "\n",
    "model = CNMP(d_x, d_y, d_SM).double()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "losses = []\n",
    "errors = []\n",
    "\n",
    "val_indices = [0, 1]\n",
    "\n",
    "for i in range(50_000):\n",
    "\n",
    "    obs, context, x_tar, y_tar, mask = get_training_sample(d_SM, batch_size)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    output, _ = model(obs, context, mask, x_tar)\n",
    "    loss = log_prob_loss(output, y_tar)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if i % 10000 == 0:\n",
    "        print('Iteration ' + str(i))\n",
    "    if i % 200 == 0:\n",
    "        #epoch_error = validation.val(model, VAL_Y, VAL_C, d_x, d_y, d_SM)\n",
    "        #errors.append(epoch_error)\n",
    "        losses.append(loss.item())\n",
    "        if min(losses) == loss.item():\n",
    "            print('Iteration ' + str(i) + ' - Loss: ' + '%.4f' % loss.item())\n",
    "            print('Saving model...')\n",
    "            torch.save(model.state_dict(), 'save/best_models_reach_arm_v1/model_' + str(i) + '.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d4rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
